{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6819_final_(3) (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Installation & Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, install for Detectron2 PointRend Segmentation"
      ],
      "metadata": {
        "id": "BVvOz5PB2Tak"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b83bddf-7f0d-483d-d570-3be890bf359b"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "# check pytorch installation: \n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# !pip uninstall ipykernel ipython traitlets ipython_genutils\n",
        "# !pip install ipykernel ipython traitlets ipython_genutils\n",
        "from google.colab import drive, output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n",
            "1.11.0+cu113 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUmK767kWQlq"
      },
      "source": [
        "# clone the repo in order to access pre-defined configs in PointRend project\n",
        "!git clone --branch v0.6 https://github.com/facebookresearch/detectron2.git detectron2_repo\n",
        "# install detectron2 from source\n",
        "!pip install -e detectron2_repo\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for other installation options\n",
        "output.clear()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart runtime once, then continue installing"
      ],
      "metadata": {
        "id": "AyZ82Wfc2dqO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog\n",
        "coco_metadata = MetadataCatalog.get(\"coco_2017_val\")\n",
        "seg_metadata = MetadataCatalog.get(\"cityscapes_fine_instance_seg_val\")\n",
        "\n",
        "# import PointRend project\n",
        "from detectron2.projects import point_rend\n",
        "\n",
        "# style transfer model\n",
        "import os\n",
        "import json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import for style transfer model"
      ],
      "metadata": {
        "id": "Hrj5F4oZ2hRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "if not os.path.exists(\"/content/photorealistic_style_transfer\"):\n",
        "  !rm -rf '/content/photorealistic_style_transfer'\n",
        "  !git clone https://github.com/ptran1203/photorealistic_style_transfer\n",
        "%cd photorealistic_style_transfer\n",
        "\n",
        "if not os.path.exists(\"/content/tfrecords\"):\n",
        "    !wget -O /content/tfrecords.zip https://github.com/ptran1203/photorealistic_style_transfer/releases/download/v1.0/tfrecords.zip\n",
        "    !unzip /content/tfrecords.zip -d /content/\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "xjHYqsvjbZo-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "when you get error, change \"tensorflow.python.keras.applications\" to \"keras.applications\" in data_processing.py"
      ],
      "metadata": {
        "id": "DeIko4FQar1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 train.py --train-tfrec /content/tfrecords/train.tfrec\\\n",
        "#                 --val-tfrec /content/tfrecords/val.tfrec\\\n",
        "#                 --epochs 100\\\n",
        "#                 --resume\\\n",
        "#                 --batch-size 8\\\n",
        "#                 --lr 2e-4\\\n",
        "\n",
        "from model import WCT2\n",
        "from utils import read_img, download_weight, display_outputs\n",
        "import cv2"
      ],
      "metadata": {
        "id": "kH9yac6HPQk-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WCT2()\n",
        "model.load_weight('/content/photorealistic_style_transfer/checkpoints/wtc2.h5')"
      ],
      "metadata": {
        "id": "o5zPNOlM1qFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993782d1-de83-4a20-8ee9-0379ae1ef7ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Annotations and class ID references for segmentation later"
      ],
      "metadata": {
        "id": "A72Okq3D2vVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"/content/annotations\"):\n",
        "  !wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "  !unzip -o annotations_trainval2017.zip \n",
        "# %cd /content\n",
        "\n",
        "stuff_dict = {'blanket': 557916,'bridge': 384949,'counter': 74209,'curtain': 405970,'floor-wood': 573094,'flower': 565607,'fruit':  489305,'house': 356169,'rock':361180,'wall-stone':361180,\n",
        "'pillow': 557916,'platform': 290293,'playingfield': 135604,'railroad': 558421,'river': 220858,'road': 179265,'roof': 82821,'sand': 454798,'sea': 214703,'shelf': 302030,'snow': 247838,\n",
        "'towel': 384808,'wall-brick': 421923,'wall-tile': 262440,'wall-wood': 350054,'water': 214703,'window-blind': 573094,'tree': 179265,'fence': 558213,'ceiling': 573094,'sky': 13348, #144114\n",
        "'cabinet': 530836,'table': 573094,'floor': 573094,'pavement': 558213,'mountain': 332318,'grass': 518213,'dirt': 242678,'paper': 278463,'food': 559513,'building': 67616,'wall': 573094,'rug': 404484,}"
      ],
      "metadata": {
        "id": "dLsLU9xN2zjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c43f904-13cb-4c58-ff93-7be28b844432"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-11 02:42:49--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.143.44\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.143.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  77.7MB/s    in 3.1s    \n",
            "\n",
            "2022-05-11 02:42:52 (77.7 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  annotations_trainval2017.zip\n",
            "  inflating: annotations/instances_train2017.json  \n",
            "  inflating: annotations/instances_val2017.json  \n",
            "  inflating: annotations/captions_train2017.json  \n",
            "  inflating: annotations/captions_val2017.json  \n",
            "  inflating: annotations/person_keypoints_train2017.json  \n",
            "  inflating: annotations/person_keypoints_val2017.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import COCO API"
      ],
      "metadata": {
        "id": "FTksR0yglkTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "dataDir='..'\n",
        "dataType='val2017'\n",
        "annFile='annotations/instances_val2017.json'.format(dataDir,dataType)\n",
        "# initialize COCO api for instance annotations\n",
        "coco=COCO(annFile)"
      ],
      "metadata": {
        "id": "22KoJkpXljuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070eb34c-7be7-49b7-90ee-477edb703b08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.70s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "object detection predictor"
      ],
      "metadata": {
        "id": "qQCOeQdIGH5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load predictor model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "catalog = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])"
      ],
      "metadata": {
        "id": "W5m1ItYjyMuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987e30a1-65d8-48be-b101-9f26b0c4cb36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_cafdb1.pkl: 261MB [00:05, 51.3MB/s]                           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a"
      },
      "source": [
        "# Segment Image and get Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKyUL4pngvE"
      },
      "source": [
        "We first download an image from the COCO dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq9GY37ml1kr"
      },
      "source": [
        "!wget https://farm9.staticflickr.com/8302/7877972164_51f717def0_z.jpg -q -O input.jpg\n",
        "\n",
        "image_size = 512\n",
        "\n",
        "def load_inputs(input_file=\"input.jpg\", image_size=image_size):\n",
        "  # save source image for comparison later\n",
        "  colored_source_img = read_img(input_file, image_size)\n",
        "  colored_source_img = cv2.cvtColor(colored_source_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # create grayscale image to color\n",
        "  im = cv2.imread(input_file,0)\n",
        "  source_img = Image.fromarray(im)\n",
        "  source_img.save(\"/content/content.jpeg\")\n",
        "  source_img = read_img(\"/content/content.jpeg\", image_size, expand_dims=True)\n",
        "  im = source_img[0]\n",
        "\n",
        "  # display\n",
        "  # cv2_imshow(colored_source_img)\n",
        "  # cv2_imshow(im)\n",
        "\n",
        "  return im, colored_source_img\n",
        "\n",
        "# im, colored_source = load_inputs()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM1thbN-ntjI"
      },
      "source": [
        "Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image. We make a prediction using Panoptic Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkPgSoYvVAEe"
      },
      "source": [
        "# Inference with a panoptic segmentation model\n",
        "def get_masks_and_classes(im):\n",
        "\n",
        "  # run predictor model\n",
        "  outputs = predictor(im)\n",
        "\n",
        "  # get segmentation info for binary masking later\n",
        "  panoptic_seg, segments_info = outputs[\"panoptic_seg\"]\n",
        "\n",
        "  mask = outputs[\"sem_seg\"].argmax(dim=0).to(\"cpu\")\n",
        "  seg_mask = panoptic_seg.to(\"cpu\")\n",
        "\n",
        "  # visualize segmentation\n",
        "  v = Visualizer(im[:, :, ::-1], catalog, scale=1.2)\n",
        "  out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
        "  # cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "  # classes_in_seg = torch.unique(panoptic_seg.to(\"cpu\"))\n",
        "  pointer_to_things = {}\n",
        "  # print(segments_info)\n",
        "  for s in segments_info:\n",
        "    if 'instance_id' not in s:\n",
        "      continue\n",
        "    if s['category_id'] not in pointer_to_things:\n",
        "      pointer_to_things[s['category_id']] = [s['id']]\n",
        "    else:\n",
        "      pointer_to_things[s['category_id']].append(s['id'])\n",
        "\n",
        "  return mask, seg_mask, pointer_to_things, segments_info\n",
        "\n",
        "# mask, seg_mask, pointer_to_things, segments_info, catalog = get_masks_and_classes(im)\n",
        "\n",
        "# # print(classes_in_seg)\n",
        "# print(pointer_to_things)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, find all classes and corresponding class IDs found during segmentation"
      ],
      "metadata": {
        "id": "WEFMptfC3Nw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all classes found in image\n",
        "def get_categories(segments_info):\n",
        "  cats_in_image = set()\n",
        "  pointer_to_cat = {}\n",
        "  for seg in segments_info:\n",
        "    id_x = seg['category_id']\n",
        "    if seg['isthing']:\n",
        "      cats_in_image.add(catalog.thing_classes[id_x])\n",
        "      pointer_to_cat[id_x] = catalog.thing_classes[id_x]\n",
        "    else:\n",
        "      cats_in_image.add(catalog.stuff_classes[id_x])\n",
        "      pointer_to_cat[id_x] = catalog.stuff_classes[id_x]\n",
        "\n",
        "  class_ids = list(pointer_to_cat.keys())\n",
        "  return cats_in_image, pointer_to_cat, class_ids\n",
        "\n",
        "# cats_in_image, pointer_to_cat, class_ids = get_categories(catalog, segments_info)\n",
        "\n",
        "# print(cats_in_image)\n",
        "# print(pointer_to_cat)"
      ],
      "metadata": {
        "id": "2ZH_9MQhZNNt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Style Transfer"
      ],
      "metadata": {
        "id": "ssWAtiyiUI-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are all functions used for binary mask style transfer"
      ],
      "metadata": {
        "id": "zC3KIn6b3bZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_masked_image(class_id, masks, original_image, pointer_to_things):\n",
        "    mask = masks[\"sem_seg\"]\n",
        "    seg_mask = masks[\"pan_seg\"]\n",
        "    if class_id in mask: # if in background\n",
        "      binary_mask = (mask.to(\"cpu\") == class_id).numpy().astype(np.uint8)\n",
        "    else:\n",
        "      if class_id in pointer_to_things: # if in foreground\n",
        "        # print(\"using panoptic mask\")\n",
        "        binary_mask = (seg_mask.to(\"cpu\") == pointer_to_things[class_id][0]).numpy().astype(np.uint8)\n",
        "\n",
        "        # if there are multiple of the same class\n",
        "        if len(pointer_to_things[class_id]) > 1:\n",
        "          for i in range(1, len(pointer_to_things[class_id])):\n",
        "            binary_mask += (seg_mask.to(\"cpu\") == pointer_to_things[class_id][i]).numpy().astype(np.uint8)\n",
        "      else: # if can't be found, default\n",
        "        # print(\"could not find mask\")\n",
        "        binary_mask = (mask.to(\"cpu\") == 0).numpy().astype(np.uint8)\n",
        "    mask_im = binary_mask[:, :, None] * original_image\n",
        "    # print(\"masked image\")\n",
        "    # print(mask_im)\n",
        "    # io.imshow(Image.fromarray(mask_im.astype('uint8')))\n",
        "    return mask_im\n",
        "\n",
        "def get_color_image(cat):\n",
        "  \"\"\"\n",
        "  retrieve a color image based on category from COCO dataset\n",
        "  \"\"\"\n",
        "  if cat in catalog.thing_classes:\n",
        "    imgIds = coco.getImgIds(catIds=coco.getCatIds(catNms=[cat]))\n",
        "    img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])\n",
        "    # print(img)\n",
        "    img = img[0]\n",
        "  else:\n",
        "    try:\n",
        "      img = coco.loadImgs(ids=stuff_dict[cat])[0]\n",
        "    except KeyError:\n",
        "      img = coco.loadImgs(ids=stuff_dict['rock'])[0] # load a generically gray image as filler\n",
        "  \n",
        "  I = io.imread(img['coco_url'])\n",
        "  return I\n",
        "\n",
        "# for cat in cats_in_image:\n",
        "#   plt.imshow(get_color_image(cat))\n",
        "#   plt.show()\n",
        "\n",
        "def style_transfer(content, idx, masks, pointers):\n",
        "\n",
        "  image_size = 512\n",
        "  content = read_img(\"/content/content.jpeg\", image_size, expand_dims=True)\n",
        "  \n",
        "  gen = np.array([[np.nan]])\n",
        "\n",
        "  # ensure we are choosing an image that applies style correctly\n",
        "  tries = 0\n",
        "  while np.isnan(gen[0]).any() and tries < 10:\n",
        "    # print(\"grabbing style\")\n",
        "    style = get_color_image(pointers[\"cat\"][idx])\n",
        "    style_img = Image.fromarray(style)\n",
        "    style_img.save(\"/content/style.jpeg\")\n",
        "    \n",
        "    style = read_img(\"/content/style.jpeg\", image_size, expand_dims=True)\n",
        "    # print(\"about to attempt transfer\")\n",
        "    gen = model.transfer(content, style, 1.0)\n",
        "    tries += 1\n",
        "  \n",
        "  if tries >= 10: # can't find a style, so return b&w\n",
        "    return make_masked_image(idx, masks, content[0], pointers[\"things\"])\n",
        "\n",
        "  cv2.imwrite('/content/test.png', gen[0][...,::-1]) # save image\n",
        "  # print(\"style transferred\")\n",
        "  # display_outputs(content[0], style[0], gen[0])\n",
        "  # gen[0] is our output pre-mask\n",
        "  # print(gen[0])\n",
        "\n",
        "  return make_masked_image(idx, masks, gen[0], pointers[\"things\"])\n",
        "\n",
        "# Image.fromarray(final_image.astype('uint8'))"
      ],
      "metadata": {
        "id": "P8knsvSyYsKK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run style transfer on each class"
      ],
      "metadata": {
        "id": "cJW6nV933efE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_colorization(class_ids, im, masks, pointers):\n",
        "  final_image = None\n",
        "  for c in class_ids:\n",
        "    # print(c)\n",
        "    if final_image is None:\n",
        "      final_image = style_transfer(im, c, masks, pointers)\n",
        "    else:\n",
        "      final_image += style_transfer(im, c, masks, pointers)\n",
        "\n",
        "  return final_image\n",
        "\n",
        "# save and display result\n",
        "# final_result = full_colorization(class_ids, im)\n",
        "# final_image = Image.fromarray(final_result.astype('uint8'))\n",
        "# final_image.save(\"/content/result.jpeg\")\n",
        "# final_image"
      ],
      "metadata": {
        "id": "8G5dq4kbILfv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def colorize(input_file=\"input.jpg\", save_path=\"/content/result.jpeg\"):\n",
        "  im, colored_source = load_inputs(input_file=input_file)\n",
        "  # print(\"got inputs\")\n",
        "\n",
        "  mask, seg_mask, pointer_to_things, segments_info = get_masks_and_classes(im)\n",
        "\n",
        "  cats_in_image, pointer_to_cat, class_ids = get_categories(segments_info)\n",
        "  # print(\"segmented\")\n",
        "\n",
        "  final_result = full_colorization(class_ids, im, {\"sem_seg\":mask, \"pan_seg\":seg_mask}, {\"cat\":pointer_to_cat, \"things\":pointer_to_things})\n",
        "\n",
        "  final_image = Image.fromarray(final_result.astype('uint8'))\n",
        "  # print('saving')\n",
        "  final_image.save(save_path)\n",
        "\n",
        "  return final_result, final_image"
      ],
      "metadata": {
        "id": "k9KrMAfUmYNS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result, final_img = colorize()\n",
        "# final_img"
      ],
      "metadata": {
        "id": "B5j1ztnpuexO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# quantitative comparison"
      ],
      "metadata": {
        "id": "XajuucIZDgzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def compare_rgb(source_path, result_path, epsilon=10, image_size=image_size):\n",
        "  \"\"\"\n",
        "  calculate color distance based on https://www.compuphase.com/cmetric.htm \n",
        "  \"\"\"\n",
        "  og = read_img(source_path, image_size)\n",
        "  og = cv2.cvtColor(og, cv2.COLOR_BGR2RGB)\n",
        "  colored = read_img(result_path, image_size)\n",
        "  colored = cv2.cvtColor(colored, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  h, w, channels = np.array(og).shape\n",
        "  total_px = h*w\n",
        "  correct_px = 0\n",
        "  for x in range(h):\n",
        "    for y in range(w):\n",
        "      dist = 0\n",
        "      rmean = (og[x,y,0] + colored[x,y,0])/2\n",
        "      rgb_diff = og[x,y] - colored[x,y]\n",
        "      r_term = (2+(rmean/256)) * (rgb_diff[0]**2)\n",
        "      g_term = 4 * (rgb_diff[1]**2)\n",
        "      b_term = (2 + ((255-rmean)/256)) * (rgb_diff[2]**2)\n",
        "      color_dist = math.sqrt(r_term + g_term + b_term)\n",
        "      # print(color_dist)\n",
        "      if abs(color_dist) <= epsilon: # if within threshold\n",
        "        correct_px += 1\n",
        "          \n",
        "  return correct_px / total_px"
      ],
      "metadata": {
        "id": "Gzl8XwznDf1J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing"
      ],
      "metadata": {
        "id": "1YakCal62xGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_images():\n",
        "  test_images = {}\n",
        "  imgs_per_cat = 5\n",
        "\n",
        "  for cat in coco.cats.values():\n",
        "    cat_name = cat['name']\n",
        "    cat_id_set = set()\n",
        "    for i in range(imgs_per_cat):\n",
        "      img_id = -1\n",
        "      while img_id == -1:\n",
        "        imgs_in_cat = coco.getImgIds(catIds=[cat['id']])\n",
        "        img = coco.loadImgs(imgs_in_cat[np.random.randint(0,len(imgs_in_cat))])\n",
        "        img_id = img[0]['id']\n",
        "        if img_id in cat_id_set: # ensure no repeats\n",
        "          img_id = -1\n",
        "      cat_id_set.add(img_id)\n",
        "    \n",
        "    test_images[cat_name] = cat_id_set\n",
        "\n",
        "  return test_images"
      ],
      "metadata": {
        "id": "wIdlr0Qx0cZq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# shutil.rmtree('/content/results/chair')"
      ],
      "metadata": {
        "id": "01WEQAJCN_dX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# get random images per category\n",
        "test_imgs = get_test_images()\n",
        "print(test_imgs)\n",
        "\n",
        "# create results\n",
        "data_dir = \"/content/results/\"\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  %cd /content\n",
        "  os.mkdir(data_dir)\n",
        "\n",
        "# csv file\n",
        "csv_file_name = data_dir + 'accuracy_data.csv'\n",
        "csv_header = ['COCO id', 'accuracy']\n",
        "with open(csv_file_name, 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow(csv_header)\n",
        "\n",
        "\n",
        "# for progress check\n",
        "count = 0\n",
        "total_count = 160\n",
        "\n",
        "# run colorization on all test images\n",
        "for cat, imgs in test_imgs.items():\n",
        "  # if cat in ['orange','broccoli','carrot','hot dog','pizza','donut','cake','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','tennis racket','bottle','skis','snowboard','sports ball','kite','baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'giraffe','umbrella', 'handbag', 'backpack', 'tie','suitcase','frisbee','cow','elephant','bear','zebra','horse','sheep','boat','truck','airplane','bicycle','car','motorcycle','person','bus','train','cat','dog','bird','bench','parking meter','stop sign','fire hydrant','traffic light']:\n",
        "  #   continue\n",
        "\n",
        "  print(cat)\n",
        "  #create category directory\n",
        "  dir_loc = data_dir + cat \n",
        "  if not os.path.exists(dir_loc):\n",
        "    try:\n",
        "        os.mkdir(dir_loc)\n",
        "    except FileExistsError:\n",
        "        print('Directory {} already exists'.format(dir_loc))\n",
        "    else:\n",
        "        print('Directory {} created'.format(dir_loc))\n",
        "\n",
        "  for i in imgs:\n",
        "    # save input image\n",
        "    input_name = str(i) + \"_input.jpeg\"\n",
        "    file_loc = dir_loc + \"/\" + input_name\n",
        "    input_image = coco.loadImgs(i)[0]\n",
        "    input_image = io.imread(input_image['coco_url'])\n",
        "    input_image = Image.fromarray(input_image)\n",
        "    input_image.save(file_loc)\n",
        "\n",
        "    # save result image\n",
        "    save_loc = dir_loc + \"/\" + str(i) + \"_result.jpeg\"\n",
        "    final_result, final_image = colorize(input_file=file_loc, save_path=save_loc)\n",
        "\n",
        "    # calc accuracy and add to csv file\n",
        "    img_acc = compare_rgb(file_loc, save_loc, epsilon=650)\n",
        "      # First, open the old CSV file in append mode, hence mentioned as 'a'\n",
        "      # Then, for the CSV file, create a file object\n",
        "    with open(csv_file_name, 'a', newline='') as f_object:  \n",
        "        # Pass the CSV  file object to the writer() function\n",
        "        writer_object = csv.writer(f_object)\n",
        "        # Pass the data in the list as an argument into the writerow() function\n",
        "        writer_object.writerow([i, img_acc])  \n",
        "        f_object.close()\n",
        "\n",
        "    count += 1\n",
        "    print(count, \" out of \", total_count)\n",
        "\n",
        "print(\"finished, check results folder\")"
      ],
      "metadata": {
        "id": "JjAUh2u622sB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe4b420-3572-49ad-c241-5f519c11ff21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'person': {101068, 148719, 571857, 569976, 97337}, 'bicycle': {50145, 350122, 169996, 458223, 306136}, 'car': {191013, 228942, 345361, 33109, 17627}, 'motorcycle': {227399, 336232, 81394, 147740, 408830}, 'airplane': {477441, 425221, 490413, 52017, 379453}, 'bus': {76416, 338625, 380706, 128051, 82846}, 'train': {363072, 492937, 146825, 184400, 151857}, 'truck': {336587, 491213, 148719, 400815, 281693}, 'boat': {427649, 160772, 36678, 61418, 289741}, 'traffic light': {125572, 385190, 555050, 39484, 423229}, 'fire hydrant': {338560, 8899, 161128, 9769, 306893}, 'stop sign': {369442, 222094, 15440, 724, 100283}, 'parking meter': {67616, 179265, 129062, 53994, 162366}, 'bench': {361730, 325031, 259690, 48504, 166747}, 'bird': {119233, 383339, 227187, 473015, 315001}, 'cat': {101762, 551815, 311789, 264441, 112798}, 'dog': {385997, 479155, 286422, 246454, 395801}, 'horse': {384513, 134856, 367818, 377486, 100510}, 'sheep': {154947, 207728, 547383, 546556, 176606}, 'cow': {200667, 137576, 289393, 133778, 559099}, 'elephant': {201025, 270402, 293300, 178618, 132796}, 'bear': {519688, 513484, 20247, 203546, 104603}, 'zebra': {60770, 290833, 236730, 501243, 454750}, 'giraffe': {47010, 301981, 449909, 445365, 296317}, 'backpack': {371042, 30828, 301135, 16249, 132796}, 'umbrella': {16228, 416104, 492362, 496854, 275198}, 'handbag': {146667, 301135, 127092, 42102, 2685}, 'tie': {293794, 52007, 258541, 78843, 476415}, 'suitcase': {360097, 287874, 292456, 47819, 358525}, 'frisbee': {291619, 364102, 409198, 319184, 239857}, 'skis': {401250, 378244, 33104, 186042, 567740}, 'snowboard': {562818, 142790, 447465, 387916, 95155}, 'sports ball': {196141, 403122, 33368, 559547, 179487}, 'kite': {224675, 530470, 163117, 67406, 511760}, 'baseball bat': {6471, 404923, 429690, 559547, 84031}, 'baseball glove': {276804, 6471, 62355, 95862, 197658}, 'skateboard': {535306, 451084, 93717, 538458, 579902}, 'surfboard': {493864, 51976, 21879, 252701, 364126}, 'tennis racket': {269121, 35279, 475191, 270908, 407646}, 'bottle': {210855, 88040, 578922, 229358, 190236}, 'wine glass': {151938, 7818, 146358, 450202, 3934}, 'cup': {465129, 345356, 460494, 210032, 324927}, 'fork': {376322, 352900, 572678, 493799, 99039}, 'knife': {530146, 352900, 331817, 209530, 2431}, 'spoon': {226147, 181796, 435081, 450100, 215644}, 'bowl': {153632, 290081, 144003, 165831, 523100}, 'banana': {352618, 163951, 37777, 66706, 468925}, 'apple': {388903, 565776, 376307, 280891, 185599}, 'sandwich': {572900, 213255, 265518, 293044, 113589}, 'orange': {148707, 217753, 304984, 359833, 185599}, 'broccoli': {25986, 551660, 34257, 248980, 61658}, 'carrot': {435081, 284106, 221872, 293044, 203095}, 'hot dog': {293858, 283268, 480936, 289938, 581206}, 'pizza': {488166, 232489, 206027, 340015, 197022}, 'donut': {69224, 383337, 363666, 260470, 38678}, 'cake': {420840, 158956, 493334, 47801, 216636}, 'chair': {350148, 573094, 286182, 446522, 491867}, 'couch': {455937, 355240, 195754, 546964, 219578}, 'potted plant': {136033, 331817, 530975, 106235, 278463}, 'bed': {291490, 521509, 115885, 249550, 213422}, 'dining table': {351810, 85157, 457262, 339442, 139260}, 'toilet': {431140, 117914, 55002, 144798, 357567}, 'tv': {363840, 494913, 179392, 17379, 560312}, 'laptop': {393569, 344100, 516916, 111609, 222299}, 'mouse': {148620, 333772, 325838, 507575, 529148}, 'remote': {379842, 300341, 229111, 468954, 543581}, 'keyboard': {160556, 366225, 255165, 409630, 1503}, 'cell phone': {537991, 547336, 16598, 346968, 226171}, 'microwave': {419653, 313130, 7574, 540502, 109976}, 'oven': {246436, 419974, 226984, 530836, 445658}, 'toaster': {175364, 135561, 173008, 453302, 66841}, 'sink': {529568, 580294, 308799, 501523, 229311}, 'refrigerator': {565776, 150417, 24243, 78266, 404191}, 'book': {509699, 366884, 35279, 121586, 167159}, 'clock': {447169, 581482, 164363, 512248, 402334}, 'vase': {89045, 559543, 502136, 87742, 19742}, 'scissors': {458663, 173008, 368982, 367095, 255483}, 'teddy bear': {362434, 537802, 446703, 478393, 189436}, 'hair drier': {239041, 500464, 350002, 315219, 501368}, 'toothbrush': {569917, 544519, 492878, 465179, 372349}}\n",
            "person\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/detectron2_repo/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in ubyte_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  out of  160\n",
            "2  out of  160\n",
            "3  out of  160\n",
            "4  out of  160\n",
            "5  out of  160\n",
            "bicycle\n",
            "Directory /content/results/bicycle created\n",
            "6  out of  160\n",
            "7  out of  160\n",
            "8  out of  160\n",
            "9  out of  160\n",
            "10  out of  160\n",
            "car\n",
            "Directory /content/results/car created\n",
            "11  out of  160\n",
            "12  out of  160\n",
            "13  out of  160\n",
            "14  out of  160\n",
            "15  out of  160\n",
            "motorcycle\n",
            "Directory /content/results/motorcycle created\n",
            "16  out of  160\n",
            "17  out of  160\n",
            "18  out of  160\n",
            "19  out of  160\n",
            "20  out of  160\n",
            "airplane\n",
            "Directory /content/results/airplane created\n",
            "21  out of  160\n",
            "22  out of  160\n",
            "23  out of  160\n",
            "24  out of  160\n",
            "25  out of  160\n",
            "bus\n",
            "Directory /content/results/bus created\n",
            "26  out of  160\n",
            "27  out of  160\n",
            "28  out of  160\n",
            "29  out of  160\n",
            "30  out of  160\n",
            "train\n",
            "Directory /content/results/train created\n",
            "31  out of  160\n",
            "32  out of  160\n",
            "33  out of  160\n",
            "34  out of  160\n",
            "35  out of  160\n",
            "truck\n",
            "Directory /content/results/truck created\n",
            "36  out of  160\n",
            "37  out of  160\n",
            "38  out of  160\n",
            "39  out of  160\n",
            "40  out of  160\n",
            "boat\n",
            "Directory /content/results/boat created\n",
            "41  out of  160\n",
            "42  out of  160\n",
            "43  out of  160\n",
            "44  out of  160\n",
            "45  out of  160\n",
            "traffic light\n",
            "Directory /content/results/traffic light created\n",
            "46  out of  160\n",
            "47  out of  160\n",
            "48  out of  160\n",
            "49  out of  160\n",
            "50  out of  160\n",
            "fire hydrant\n",
            "Directory /content/results/fire hydrant created\n"
          ]
        }
      ]
    }
  ]
}